# -*- coding: utf-8 -*-
"""Restaurant recommendation system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jpAYxjxmnwY18fcqaLDxFICxgtwyIVvV
"""

import numpy as np
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt
import plotly.offline as py
import plotly.graph_objs as go
import seaborn as sns
import nltk
from nltk.corpus import stopwords
from sklearn.metrics.pairwise import linear_kernel
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

data = pd.read_csv('/content/HyderabadResturants.csv')
df=data
df.head()

df.info()

df.shape

df.columns

df.isnull().sum()

"""**Data cleaning**"""

df=df.drop(['links'], axis=1)

df.dropna(how='any', inplace=True)

df.duplicated().sum()
df.drop_duplicates(inplace=True)

df=df.rename(columns={'price for one':'price','ratings':'rating','names':'name'})

df[["cuisine1", "cuisine2",'cuisine3','cuisine4' ,'cuisine5','cuisine6','cuisine7','cuisine8']] = (  # Create two new features
    df["cuisine"]           # from the cuisine feature
    .str                         # through the string accessor
    .split(",", expand=True)     # by splitting on ","
                                 # and expanding the result into separate columns
)

df.head()

#df=df.drop(['cuisine'], axis=1)

df.head()

"""**Data Visualization**"""

#Most Famous 5 restaurants in Banglore
plt.figure(figsize=(17,7))
chains=df['name'].value_counts(10)[:5]
sns.barplot(x=chains.index, y=chains, palette='tab10')
plt.title("Most famous restaurants in Hyderabad")
plt.ylabel("Number of outlets")

# Distribution of Restaurant Rating
import matplotlib.pyplot as plt
import seaborn as sns

# Convert 'rating' column to numeric, handling non-numeric values
df['rating'] = pd.to_numeric(df['rating'], errors='coerce') # 'coerce' will set non-numeric values to NaN

fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))
sns.distplot(df.rating.dropna(), kde=False, color='b', ax=ax, bins=20) # Drop NaN values for plotting
ax.axvline(df.rating.dropna().mean(), 0, 1, color='r', label='Mean')
ax.legend()
ax.set_ylabel('Count', size=20)
ax.set_xlabel('Rate', size=20)
ax.set_title('Distribution (count) of Restaurant rating', size=20)
plt.show()

# Top 10 Rated Restaurants
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming df contains your restaurant data with ratings

# Calculate mean rating per restaurant
mean_rating = df.groupby('name')['rating'].mean().reset_index()

# Sort by mean rating in descending order and select top 10
top_10_rating = mean_rating.sort_values(by='rating', ascending=False).head(10)

# Plotting
plt.figure(figsize=(10, 7))
sns.barplot(data=top_10_rating, x='rating', y='name', palette='RdBu')
plt.title('Top Rated 10 Restaurants')
plt.xlabel('Mean Rating')
plt.ylabel('Restaurant Name')
plt.show()

# Top 15 two word frequencies for Cuisines
def get_top_words(text, n, ngram_range):
    vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words='english')
    X = vectorizer.fit_transform(text)
    word_freq = X.sum(axis=0).A1
    words = vectorizer.get_feature_names_out()
    word_count = list(zip(words, word_freq))
    word_count = sorted(word_count, key=lambda x: x[1], reverse=True)[:n]
    return word_count
lst = get_top_words(df['cuisine'], 15, (2,))
df_words = pd.DataFrame(lst, columns=['Word', 'Count'])
plt.figure(figsize=(10, 5))
sns.barplot(data=df_words, x='Count', y='Word')
plt.title('Word Couple Frequency for Cuisines')
plt.show()

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Assuming 'df' is your DataFrame containing restaurant data

# Convert 'cuisine' column to a list
feature = df["cuisine"].tolist()

# Create the TF-IDF matrix
tfidf = TfidfVectorizer(stop_words="english")
tfidf_matrix = tfidf.fit_transform(feature)

# Compute cosine similarity
similarity = cosine_similarity(tfidf_matrix)

# Create a Series with restaurant indices
indices = pd.Series(df.index, index=df['name']).drop_duplicates()

def restaurant_recommendation(name, similarity=similarity):
    # Get the index of the restaurant
    index = indices[name]

    # Get similarity scores for the restaurant
    similarity_scores = list(enumerate(similarity[index]))

    # Sort the restaurants based on similarity scores
    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)

    # Get the top 10 similar restaurants
    similarity_scores = similarity_scores[1:11]

    # Get the indices and similarity scores of the top 10 similar restaurants
    restaurant_indices = [i[0] for i in similarity_scores]
    similarity_scores = [i[1] for i in similarity_scores]

    # Retrieve restaurant names and create a DataFrame
    recommendations = df.iloc[restaurant_indices][['name']].copy()
    recommendations['similarity_score'] = similarity_scores

    return recommendations

print(restaurant_recommendation('Paradise Biryani'))

print(restaurant_recommendation('KFC'))

print(restaurant_recommendation('Sahara Bakers'))

